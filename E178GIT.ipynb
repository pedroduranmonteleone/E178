{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    from astropy.table import Table\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.cluster import KMeans\n",
    "    import numpy as np\n",
    "    import csv\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import statsmodels.api as sm\n",
    "    from scipy.stats import pearsonr\n",
    "    from kneed import KneeLocator\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from astropy.io import fits\n",
    "\n",
    "\n",
    "\n",
    "    # Read the data from the FITS file\n",
    "    filename = 'C:/Users/pedro/Downloads/StellarMasses.fits'\n",
    "    table = Table.read(filename)\n",
    "\n",
    "    n_datapoints = len(table)\n",
    "    print(f'The dataset contains {n_datapoints} datapoints.')\n",
    "\n",
    "    # Convert the table to a pandas dataframe\n",
    "    df = table.to_pandas()\n",
    "\n",
    "    #drop redundant features\n",
    "    redundant_cols = df.filter(like='absmag_').columns.difference(df.filter(like='absmag_*_stars').columns)\n",
    "    df.drop(redundant_cols, axis=1, inplace=True)\n",
    "\n",
    "    # Select only the numerical columns for normalization\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_data = df[numeric_cols]\n",
    "\n",
    "    # Normalize the data using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(numeric_data)\n",
    "    \n",
    "    normalized_df = pd.DataFrame(normalized_data, columns=numeric_cols)\n",
    "\n",
    "    # Calculate the correlation coefficient between each feature and the redshift\n",
    "    correlations = normalized_df.corr()['Z']\n",
    "\n",
    "\n",
    "    # Select the top features with the highest absolute correlation coefficient\n",
    "    n_features = 100  # Select the number of top features to display\n",
    "    top_features = abs(correlations).nlargest(n_features).index.tolist()\n",
    "\n",
    "    # Print the names of the top features\n",
    "    print(f'Top {n_features} features that correlate with redshift:')\n",
    "    for feature in top_features:\n",
    "        print(feature)\n",
    "\n",
    "\n",
    "\n",
    "    # Select the features for clustering\n",
    "    features = ['S2N', 'dellogLWage', 'dellogmoverl_i', 'nQ', 'PPP','Z','logmstar']\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Create a new dataframe with only the selected features\n",
    "    X = normalized_df[features]\n",
    "    #Separate target variable from other features\n",
    "    X = X.drop('Z', axis=1)\n",
    "    Y=normalized_df[features]['Z']\n",
    "    print(f\"This is Z {Y}\" )\n",
    "\n",
    "    # Set the number of clusters\n",
    "    n_clusters = 3\n",
    "\n",
    "    # Perform k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "\n",
    "    normalized_df['cluster'] = kmeans.labels_\n",
    "\n",
    "\n",
    "    # determine the optimal value of k\n",
    "    kl = KneeLocator(K, distortions, curve=\"convex\", direction=\"decreasing\")\n",
    "    optimal_k = kl.elbow\n",
    "    print(\"Optimal k value: \", optimal_k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Apply K-means clustering to select the most important features\n",
    "    kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "    X_clusters = kmeans.fit_predict(X)\n",
    "    important_features = []\n",
    "    for cluster in range(5):\n",
    "        cluster_indices = X_clusters == cluster\n",
    "        cluster_X = X.loc[cluster_indices, :]\n",
    "        cluster_kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        cluster_kmeans.fit(cluster_X)\n",
    "        cluster_center = cluster_kmeans.cluster_centers_.mean(axis=0)\n",
    "        important_feature = cluster_X.columns[abs(cluster_X.mean() - cluster_center).argmax()]\n",
    "        important_features.append(important_feature)\n",
    "\n",
    "    # Select the important features and split the dataset into training and testing sets\n",
    "    X = X[important_features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a linear regression model on the selected features\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the testing set\n",
    "    score = lr.score(X_test, y_test)\n",
    "    print(f\"Model accuracy: {score}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
